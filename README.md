# Classification of Malware(CLaMP-16)

This repository contains my thesis work on malware classification using the **CLaMP** dataset from Kaggle. The project was implemented in **Python**, executed through **Jupyter Notebooks**, and includes two versions of the notebook that document the progression of the thesis project:
        ğŸ”¹ **CLaMP16_malware_classification_v1.ipynb** â€” Initial Version
        ğŸ”¹ **CLaMP16_malware_classification.ipynb** â€” Updated/Final Version

## ğŸ“ Repository Structure

CLaMP-16/
â”œâ”€â”€ notebooks/
â”‚ â”œâ”€â”€ CLaMP16_malware_classification_v1.ipynb # Initial version
â”‚ â””â”€â”€ CLaMP16_malware_classification.ipynb # Updated/final version
â”œâ”€â”€ data/ # (Optional) Kaggle dataset files
â”œâ”€â”€ requirements.txt # Python dependencies
â””â”€â”€ README.md # This file


## ğŸ“ Notebooks Overview

### ğŸ“˜ `CLaMP16_malware_classification_v1.ipynb`


### ğŸ“™ `CLaMP16_malware_classification_v2.ipynb`


## ğŸ› ï¸ Installation & Setup

1. **Clone the repo**  
   ```bash
   git clone https://github.com/R3nch00/CLaMP-16.git
   cd CLaMP-16

2. **Install dependencies**
   ```bash
   pip install -r requirements.txt

3. **[Optional] Download the CLaMP dataset**
   â€¢	Source: Kaggle (â€œCLaMP â€“ Malware Classificationâ€)
   â€¢	Save CSV files under data/

4. **Launch Jupyter Notebook**
   ```bash
   jupyter notebook notebooks/

5. **Open notebooks in detail**
   â€¢	v1.ipynb: Original pipeline and baseline
   â€¢	.ipynb: Final, polished modeling steps

## ğŸ“Š Methodology
Malware classification pipeline was developed through a structured and iterative approach involving data preprocessing, model experimentation, and performance evaluation. The key stages of the methodology are as follows
  ğŸ§¹ **Data Loading & Cleaning** - Loaded and cleaned CLaMP dataset: handled missing values; label-encoded categories; normalized features
  ğŸ“Š **Exploratory Data Analysis (EDA)** - Visualized class distributions, feature correlations, and stats; identified imbalances to guide preprocessing
  ğŸ› ï¸ **Feature Engineering** - Selected key features via correlation and importance; applied dimensionality reduction; prepared data for ML and DL models
  ğŸ¤– **Model Training** - The project involves extensive experimentation with both machine learning and deep learning models for malware classification using the CLaMP dataset
        ğŸ”¹ Traditional Machine Learning Models - These models were trained with varying feature sets and evaluated using standard classification metrics (accuracy, precision, recall, F1-score, ROC-AUC).
              K-Nearest Neighbors (KNN)
              Random Forest (RF)
              Naive Bayes (NB)
              AdaBoost
              Logistic Regression (LR)
              Decision Tree (DT)
              Linear Discriminant Analysis (LDA)
``
        ğŸ”¹ Deep Learning Models - Deep learning models were implemented using TensorFlow/Keras and trained on processed numerical features. Hyperparameter tuning and architectural variations were applied to optimize performance.
              Multilayer Perceptron (MLP)
              1D Convolutional Neural Network (1D-CNN)
              Recurrent Neural Network (RNN)   
              Long Short-Term Memory (LSTM)
              Gated Recurrent Unit (GRU)
  ğŸ“ˆ **Evaluation Metrics** - Recorded, compared, and analyzed model performance to identify top approaches for CLaMP malware classification
        â€¢	Accuracy
        â€¢	Precision, Recall, and F1-Score
        â€¢	Confusion Matrix
        â€¢	ROC-AUC Curve

## âœ… Dependencies
This project was developed in Python using common data science libraries. To run the notebooks, make sure the following packages are installed -
   ```bash
   numpy
   pandas
   scikit-learn
   xgboost
   matplotlib
   seaborn
   jupyter
```
## ğŸ”® Future Work
   â€¢	Integrate deep learning (e.g., CNN or transformer models)
   â€¢	Build a REST API endpoint for real time malware prediction
   â€¢	Visualize predictions using interactive dashboards (e.g., Plotly, Dash)



ğŸ§ª Methodology
The malware classification pipeline was developed through a structured and iterative approach involving data preprocessing, model experimentation, and performance evaluation. The key stages are:

ğŸ“¥ Data Loading & Cleaning

Loaded and cleaned the CLaMP dataset

Handled missing values

Label-encoded categorical variables

Normalized numerical features

ğŸ“Š Exploratory Data Analysis (EDA)

Visualized class distributions and feature correlations

Identified imbalances to guide preprocessing

ğŸ› ï¸ Feature Engineering

Selected key features based on correlation and importance

Applied dimensionality reduction techniques

Prepared datasets for ML and DL models
